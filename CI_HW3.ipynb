{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /home/mohammad/.local/lib/python3.10/site-packages (1.23.5)\n",
      "Collecting numpy\n",
      "  Using cached numpy-1.24.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
      "Requirement already satisfied: pandas in /home/mohammad/miniconda3/lib/python3.10/site-packages (1.5.3)\n",
      "Collecting pandas\n",
      "  Downloading pandas-2.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.3 MB)\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/12.3 MB\u001b[0m \u001b[31m14.2 kB/s\u001b[0m eta \u001b[36m0:12:29\u001b[0m:41\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: Exception:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mohammad/miniconda3/lib/python3.10/site-packages/pip/_vendor/urllib3/response.py\", line 437, in _error_catcher\n",
      "    yield\n",
      "  File \"/home/mohammad/miniconda3/lib/python3.10/site-packages/pip/_vendor/urllib3/response.py\", line 560, in read\n",
      "    data = self._fp_read(amt) if not fp_closed else b\"\"\n",
      "  File \"/home/mohammad/miniconda3/lib/python3.10/site-packages/pip/_vendor/urllib3/response.py\", line 526, in _fp_read\n",
      "    return self._fp.read(amt) if amt is not None else self._fp.read()\n",
      "  File \"/home/mohammad/miniconda3/lib/python3.10/site-packages/pip/_vendor/cachecontrol/filewrapper.py\", line 90, in read\n",
      "    data = self.__fp.read(amt)\n",
      "  File \"/home/mohammad/miniconda3/lib/python3.10/http/client.py\", line 465, in read\n",
      "    s = self.fp.read(amt)\n",
      "  File \"/home/mohammad/miniconda3/lib/python3.10/socket.py\", line 705, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/home/mohammad/miniconda3/lib/python3.10/ssl.py\", line 1274, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/home/mohammad/miniconda3/lib/python3.10/ssl.py\", line 1130, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "TimeoutError: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mohammad/miniconda3/lib/python3.10/site-packages/pip/_internal/cli/base_command.py\", line 160, in exc_logging_wrapper\n",
      "    status = run_func(*args)\n",
      "  File \"/home/mohammad/miniconda3/lib/python3.10/site-packages/pip/_internal/cli/req_command.py\", line 247, in wrapper\n",
      "    return func(self, options, args)\n",
      "  File \"/home/mohammad/miniconda3/lib/python3.10/site-packages/pip/_internal/commands/install.py\", line 400, in run\n",
      "    requirement_set = resolver.resolve(\n",
      "  File \"/home/mohammad/miniconda3/lib/python3.10/site-packages/pip/_internal/resolution/resolvelib/resolver.py\", line 92, in resolve\n",
      "    result = self._result = resolver.resolve(\n",
      "  File \"/home/mohammad/miniconda3/lib/python3.10/site-packages/pip/_vendor/resolvelib/resolvers.py\", line 481, in resolve\n",
      "    state = resolution.resolve(requirements, max_rounds=max_rounds)\n",
      "  File \"/home/mohammad/miniconda3/lib/python3.10/site-packages/pip/_vendor/resolvelib/resolvers.py\", line 348, in resolve\n",
      "    self._add_to_criteria(self.state.criteria, r, parent=None)\n",
      "  File \"/home/mohammad/miniconda3/lib/python3.10/site-packages/pip/_vendor/resolvelib/resolvers.py\", line 172, in _add_to_criteria\n",
      "    if not criterion.candidates:\n",
      "  File \"/home/mohammad/miniconda3/lib/python3.10/site-packages/pip/_vendor/resolvelib/structs.py\", line 151, in __bool__\n",
      "    return bool(self._sequence)\n",
      "  File \"/home/mohammad/miniconda3/lib/python3.10/site-packages/pip/_internal/resolution/resolvelib/found_candidates.py\", line 155, in __bool__\n",
      "    return any(self)\n",
      "  File \"/home/mohammad/miniconda3/lib/python3.10/site-packages/pip/_internal/resolution/resolvelib/found_candidates.py\", line 143, in <genexpr>\n",
      "    return (c for c in iterator if id(c) not in self._incompatible_ids)\n",
      "  File \"/home/mohammad/miniconda3/lib/python3.10/site-packages/pip/_internal/resolution/resolvelib/found_candidates.py\", line 97, in _iter_built_with_inserted\n",
      "    candidate = func()\n",
      "  File \"/home/mohammad/miniconda3/lib/python3.10/site-packages/pip/_internal/resolution/resolvelib/factory.py\", line 206, in _make_candidate_from_link\n",
      "    self._link_candidate_cache[link] = LinkCandidate(\n",
      "  File \"/home/mohammad/miniconda3/lib/python3.10/site-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 297, in __init__\n",
      "    super().__init__(\n",
      "  File \"/home/mohammad/miniconda3/lib/python3.10/site-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 162, in __init__\n",
      "    self.dist = self._prepare()\n",
      "  File \"/home/mohammad/miniconda3/lib/python3.10/site-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 231, in _prepare\n",
      "    dist = self._prepare_distribution()\n",
      "  File \"/home/mohammad/miniconda3/lib/python3.10/site-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 308, in _prepare_distribution\n",
      "    return preparer.prepare_linked_requirement(self._ireq, parallel_builds=True)\n",
      "  File \"/home/mohammad/miniconda3/lib/python3.10/site-packages/pip/_internal/operations/prepare.py\", line 491, in prepare_linked_requirement\n",
      "    return self._prepare_linked_requirement(req, parallel_builds)\n",
      "  File \"/home/mohammad/miniconda3/lib/python3.10/site-packages/pip/_internal/operations/prepare.py\", line 536, in _prepare_linked_requirement\n",
      "    local_file = unpack_url(\n",
      "  File \"/home/mohammad/miniconda3/lib/python3.10/site-packages/pip/_internal/operations/prepare.py\", line 166, in unpack_url\n",
      "    file = get_http_url(\n",
      "  File \"/home/mohammad/miniconda3/lib/python3.10/site-packages/pip/_internal/operations/prepare.py\", line 107, in get_http_url\n",
      "    from_path, content_type = download(link, temp_dir.path)\n",
      "  File \"/home/mohammad/miniconda3/lib/python3.10/site-packages/pip/_internal/network/download.py\", line 147, in __call__\n",
      "    for chunk in chunks:\n",
      "  File \"/home/mohammad/miniconda3/lib/python3.10/site-packages/pip/_internal/cli/progress_bars.py\", line 53, in _rich_progress_bar\n",
      "    for chunk in iterable:\n",
      "  File \"/home/mohammad/miniconda3/lib/python3.10/site-packages/pip/_internal/network/utils.py\", line 63, in response_chunks\n",
      "    for chunk in response.raw.stream(\n",
      "  File \"/home/mohammad/miniconda3/lib/python3.10/site-packages/pip/_vendor/urllib3/response.py\", line 621, in stream\n",
      "    data = self.read(amt=amt, decode_content=decode_content)\n",
      "  File \"/home/mohammad/miniconda3/lib/python3.10/site-packages/pip/_vendor/urllib3/response.py\", line 559, in read\n",
      "    with self._error_catcher():\n",
      "  File \"/home/mohammad/miniconda3/lib/python3.10/contextlib.py\", line 153, in __exit__\n",
      "    self.gen.throw(typ, value, traceback)\n",
      "  File \"/home/mohammad/miniconda3/lib/python3.10/site-packages/pip/_vendor/urllib3/response.py\", line 442, in _error_catcher\n",
      "    raise ReadTimeoutError(self._pool, None, \"Read timed out.\")\n",
      "pip._vendor.urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='files.pythonhosted.org', port=443): Read timed out.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "## install the libraries needed\n",
    "!pip install -U numpy pandas sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_extraction\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TfidfVectorizer\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdecomposition\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PCA\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import mutual_info_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(sms_data_str):\n",
    "    \"\"\"\n",
    "    convert `sms_data_str` into a pandas dataframe\n",
    "    \"\"\"\n",
    "    data_arr = []\n",
    "\n",
    "    data_records = sms_data_str.split('\\n')[:-1]\n",
    "    for data in data_records:\n",
    "        label = None\n",
    "        sample = None\n",
    "        match data[:3]:\n",
    "            case 'ham':\n",
    "                label = 'legitimate'\n",
    "                sample = data[4:] \n",
    "            case 'spa':\n",
    "                label = 'spam'\n",
    "                sample = data[5:] \n",
    "            case _:\n",
    "                label = 'N/A'\n",
    "            \n",
    "        data_arr.append([label, sample])\n",
    "        \n",
    "    data_arr = np.array(data_arr)\n",
    "    data_label = data_arr[:, 0]\n",
    "    data_records = data_arr[:, 1]\n",
    "    \n",
    "    return data_records, data_label\n",
    "\n",
    "def tfidf_vectorizer(records):\n",
    "    vectorizer = TfidfVectorizer(\n",
    "        lowercase=True,\n",
    "        token_pattern=r'\\b[A-Za-z]+\\b', \n",
    "        norm=None\n",
    "    )\n",
    "    \n",
    "    records_transformed = vectorizer.fit_transform(records)\n",
    "\n",
    "    return records_transformed.toarray(), vectorizer.get_feature_names_out()\n",
    "\n",
    "def feature_extraction(X, n_components=5):\n",
    "    reduction_pca = PCA(\n",
    "        n_components=n_components,\n",
    "        whiten=False\n",
    "    )\n",
    "    data_reduced = reduction_pca.fit_transform(X)\n",
    "    return data_reduced\n",
    "\n",
    "def feature_selection(df_records, labels, n_components=5):\n",
    "    feature_selection_model = SelectKBest(mutual_info_classif, k=n_components) \n",
    "    ## make a selection over the best features\n",
    "    selected_record_features = feature_selection_model.fit_transform(df_records, labels)\n",
    "    \n",
    "    return selected_record_features, feature_selection_model.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sms_data_str = None\n",
    "with open('SMSSpamCollection') as file:\n",
    "    sms_data_str = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "records, labels = process_data(sms_data_str)\n",
    "records_vectorized, feature_names = tfidf_vectorizer(records)\n",
    "\n",
    "## one hot encoding labels\n",
    "labels = np.array([0 if y == 'legitimate' else 1 for y in labels] )\n",
    "\n",
    "## reducing dimension\n",
    "records_dim_reduced = feature_extraction(records_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "records_dim_reduced[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "records_vectorized = pd.DataFrame(records_vectorized, columns=feature_names)\n",
    "\n",
    "records_selection, feature_name_selection = feature_selection(records_vectorized,labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## for better visualization\n",
    "pd.DataFrame(records_selection, columns=feature_name_selection).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: build a fuzzy rule-based model for (records, label)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "2b955d226d9aa9f90a51fa3f36ce22332332eca7b3eabee7dfc09f1063aca4ef"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
